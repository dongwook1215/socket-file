#!/usr/bin/env node

/**
 * Module dependencies.
 */

var app = require('../app');
var debug = require('debug')('socket-file:server');
var http = require('http');
var fs = require('fs');
var path = require('path');

/**
 * Get port from environment and store in Express.
 */

var port = normalizePort(process.env.PORT || '3000');
app.set('port', port);

/**
 * Create HTTP server.
 */

var server = http.createServer(app);
var io = require('socket.io')(server);
var ss = require('socket.io-stream');
const async = require('async');
const AWS = require('aws-sdk');
const s3 = new AWS.S3({
  'accessKeyId': '',
  'secretAccessKey': ''
});

io.on('connection', function (socket) {
  var Files = {};

  socket.on('Download', function (data) {
    let count = 1
    let start = data.Start;
    let end = (data.End < data.Final) ? data.End : data.Final;
    let func_arr = [];
    for(let i = start;i < end; i++){
      let params = {
        Bucket: "big-data-upload-for-raccoon",
        Key: `${data.Name}/${i}`
      }
      func_arr.push(callback => getBuffer(params,callback))
    }
    async.parallel(func_arr,function(err,result){
      data.Start = data.Start + count
      data.End = data.End + count
      data.Data = Buffer.concat(result);
      console.log(data.Data);
      socket.emit('MoreDownload',data)
    })
  });

  ss(socket).on('uploading',function (stream,data){
    // stream.pipe();
    var Name = data.name;
    var Size = data.size;
    if(!Files[Name]){
      Files[Name] = {
        node: 0,
        s3: 0,
        downloaded: 0
      };
    }
    stream.on('data',chunk => {
      console.log(data);
      console.log(chunk);
      console.log(Files[Name])
      Files[Name].downloaded += chunk.length;
      Files[Name].buffer = Files[Name].buffer ? Buffer.concat([Files[Name].buffer,chunk]) : chunk;
      if(Files[Name].buffer.length > 10485760 || Files[Name].downloaded === Size){
        const params = {
          'Bucket': `big-data-upload-for-raccoon/${Name}`,
          'Key': `${Files[Name].node}`,
          'Body': Files[Name].buffer
        };
        s3.upload(params).on('httpUploadProgress', function (progress) {
          console.log('Uploaded :: ' + String(parseInt((progress.loaded * 100) / progress.total)) + '%');
        }).send(function (s3Err, data) {
          if (s3Err) throw s3Err;
          Files[Name].s3 = Files[Name].s3 + 1;
          console.log(Files[Name].s3);
        });
        Files[Name].node = Files[Name].node + 1;
        delete Files[Name].buffer;
      }
    })
    stream.on('end',() => {
      console.log('finish');
      console.log(Files);
    })
  })

});

/**
 * Listen on provided port, on all network interfaces.
 */

server.listen(port);
server.on('error', onError);
server.on('listening', onListening);

/**
 * Normalize a port into a number, string, or false.
 */

function normalizePort(val) {
  var port = parseInt(val, 10);

  if (isNaN(port)) {
    // named pipe
    return val;
  }

  if (port >= 0) {
    // port number
    return port;
  }

  return false;
}

/**
 * Event listener for HTTP server "error" event.
 */

function onError(error) {
  if (error.syscall !== 'listen') {
    throw error;
  }

  var bind = typeof port === 'string'
      ? 'Pipe ' + port
      : 'Port ' + port;

  // handle specific listen errors with friendly messages
  switch (error.code) {
    case 'EACCES':
      console.error(bind + ' requires elevated privileges');
      process.exit(1);
      break;
    case 'EADDRINUSE':
      console.error(bind + ' is already in use');
      process.exit(1);
      break;
    default:
      throw error;
  }
}

/**
 * Event listener for HTTP server "listening" event.
 */

function onListening() {
  var addr = server.address();
  var bind = typeof addr === 'string'
      ? 'pipe ' + addr
      : 'port ' + addr.port;
  debug('Listening on ' + bind);
}

function getBuffer(params,callback){
  // const url = await s3.getSignedUrl('getObject', params);
  // console.log(params);
  s3.getObject(params,function (err,newData){
    callback(null,newData.Body);
  })
}
